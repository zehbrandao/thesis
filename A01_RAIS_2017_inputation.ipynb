{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c346ba-84ee-4d60-9046-e524197a3242",
   "metadata": {},
   "source": [
    "# Wrangling 2017 Job Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db17a99-a002-4736-b8fc-0bd95626f180",
   "metadata": {},
   "source": [
    "First, this section gets a point (lon,lat) that represents each zip code location, based on data provided by the municipality of Belo Horizonte. The procedure is as follows: data is sorted by zip_code (CEP) and house number, then the geolocation of each zip code is taken to be the same as middle house number.\n",
    "\n",
    "Then, it uses that data to locate the job opportunities that are present into the _Anual Registry of Social Information_ (**RAIS**). The Registry only accounts for formal jobs, which ends up being an important limitation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8188350-b475-453e-bdc0-9ba5cef00229",
   "metadata": {},
   "source": [
    "zip code data source: http://bhmap.pbh.gov.br\n",
    "\n",
    "job data source: http://pdet.mte.gov.br/microdados-rais-e-caged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c330d0f5-6b0b-4f49-adcf-c1078103a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from shapely.geometry import mapping, Point, Polygon\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50483185-c4bb-4257-840d-475852fffcc1",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e8f4e-6126-4e48-bf5c-11e1f3a47c7a",
   "metadata": {},
   "source": [
    "### Parent Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63579773-4de9-433d-99df-1cfbf43c829f",
   "metadata": {},
   "source": [
    "These should of course be adjusted to reflect the appropriate locations in your disk or wherever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb91dce-f60f-454e-aa80-6790194e97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = os.environ.get('OUT_FOLDER')\n",
    "out_folder = pathlib.Path(out_folder)\n",
    "out_folder = out_folder / 'A'\n",
    "\n",
    "db_folder = os.environ.get('DB_FOLDER')\n",
    "db_folder = pathlib.Path(db_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e96243-5f8a-4152-a2dc-b4f62c4ed302",
   "metadata": {},
   "source": [
    "### General Purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3b86fa-a10b-43e6-b63b-fc9588857d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_zipped_path_for_gpd(path):\n",
    "    \"\"\"This gets a full path for a zipped shp file and parses it\n",
    "    into a structure that gpd.read_file() understands.\n",
    "    \"\"\"\n",
    "    prefix = r'zip://'\n",
    "    \n",
    "    try:\n",
    "        path = prefix + path.as_posix()\n",
    "    except:\n",
    "        path = pathlib.PureWindowsPath(path)\n",
    "        path = prefix + path.as_posix()\n",
    "        \n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631d0252-159e-4486-8c86-378a5768635f",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19078fbb-66f0-49e6-b5d6-f33d0255ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 31 # MG ID as int\n",
    "ibgeID = 3106200 # Belo Horizonte ID as str\n",
    "                 # Either str or int, no matter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fc28e1-8bc9-4824-b8f8-1f0289dba716",
   "metadata": {},
   "source": [
    "### Retrieving Hexagons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aefa4c05-fab4-4aba-94d5-b2bc7d2cf20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brand\\anaconda3\\envs\\pyGeo\\lib\\site-packages\\geopandas\\geodataframe.py:422: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    }
   ],
   "source": [
    "re_path = r'(BH_)(hex_\\d{1,2})(_with_land_uses\\.gpkg)'\n",
    "\n",
    "for file in out_folder.iterdir():\n",
    "    match = re.search(re_path, file.name)\n",
    "    # If there's no search result, match is None\n",
    "    if match:\n",
    "        path_to_hexes = file\n",
    "        index_name = match.group(2) # .group() is one-indexed\n",
    "                   \n",
    "hex_ = gpd.read_file(path_to_hexes, layer='2017')\n",
    "hex_.rename(columns={'index': index_name}, inplace=True)\n",
    "hex_.set_index(index_name, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848c30c5-e083-49f0-a858-50ae395f59c3",
   "metadata": {},
   "source": [
    "### Addresses and Zip Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60803e04-1d2d-4137-bc75-6e1c4b2da5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16082 invalid records: 2.21 % of instances\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDEND</th>\n",
       "      <th>ID_EDC</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>IND_ATIVO</th>\n",
       "      <th>ID_LOGRADO</th>\n",
       "      <th>SIGLA_TIPO</th>\n",
       "      <th>NOME_LOGRA</th>\n",
       "      <th>NUMERO_IMO</th>\n",
       "      <th>LETRA_IMOV</th>\n",
       "      <th>ID_BAIRRO_</th>\n",
       "      <th>...</th>\n",
       "      <th>ID_BAIRRO0</th>\n",
       "      <th>NUM_BAIRR0</th>\n",
       "      <th>TIPO_BAIRR</th>\n",
       "      <th>NOME_BAIR0</th>\n",
       "      <th>ID_REGIONA</th>\n",
       "      <th>NOME_REGIO</th>\n",
       "      <th>CEP</th>\n",
       "      <th>LESTE</th>\n",
       "      <th>NORTE</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31240900850</td>\n",
       "      <td>894158.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Sim</td>\n",
       "      <td>312409.0</td>\n",
       "      <td>RUA</td>\n",
       "      <td>SERRA DO CURRAL</td>\n",
       "      <td>850.0</td>\n",
       "      <td>None</td>\n",
       "      <td>248.0</td>\n",
       "      <td>...</td>\n",
       "      <td>225.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>Bairro</td>\n",
       "      <td>Jatobá</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BARREIRO</td>\n",
       "      <td>30668750.0</td>\n",
       "      <td>602048,069170647</td>\n",
       "      <td>7787712,71281263</td>\n",
       "      <td>POINT (602048.069 7787712.713)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31240900880</td>\n",
       "      <td>894159.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Sim</td>\n",
       "      <td>312409.0</td>\n",
       "      <td>RUA</td>\n",
       "      <td>SERRA DO CURRAL</td>\n",
       "      <td>880.0</td>\n",
       "      <td>None</td>\n",
       "      <td>248.0</td>\n",
       "      <td>...</td>\n",
       "      <td>225.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>Bairro</td>\n",
       "      <td>Jatobá</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BARREIRO</td>\n",
       "      <td>30668750.0</td>\n",
       "      <td>602054,808492864</td>\n",
       "      <td>7787717,52661422</td>\n",
       "      <td>POINT (602054.808 7787717.527)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         IDEND    ID_EDC STATUS IND_ATIVO  ID_LOGRADO SIGLA_TIPO  \\\n",
       "0  31240900850  894158.0   None       Sim    312409.0        RUA   \n",
       "1  31240900880  894159.0   None       Sim    312409.0        RUA   \n",
       "\n",
       "        NOME_LOGRA  NUMERO_IMO LETRA_IMOV  ID_BAIRRO_  ... ID_BAIRRO0  \\\n",
       "0  SERRA DO CURRAL       850.0       None       248.0  ...      225.0   \n",
       "1  SERRA DO CURRAL       880.0       None       248.0  ...      225.0   \n",
       "\n",
       "  NUM_BAIRR0  TIPO_BAIRR  NOME_BAIR0 ID_REGIONA NOME_REGIO         CEP  \\\n",
       "0      618.0      Bairro      Jatobá        1.0   BARREIRO  30668750.0   \n",
       "1      618.0      Bairro      Jatobá        1.0   BARREIRO  30668750.0   \n",
       "\n",
       "              LESTE             NORTE                        geometry  \n",
       "0  602048,069170647  7787712,71281263  POINT (602048.069 7787712.713)  \n",
       "1  602054,808492864  7787717,52661422  POINT (602054.808 7787717.527)  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _drop_invalid_addresses(addresses):\n",
    "    \"\"\"Drops addresses in which zip code\n",
    "    or house number are NaN.\n",
    "    \"\"\"\n",
    "    mask = (addresses.CEP.notnull()) & (addresses.NUMERO_IMO.notnull())\n",
    "    print(\n",
    "        f'There are {np.sum(~mask)} invalid records: '\n",
    "        f'{np.sum(~mask) / np.sum(mask) * 100 :.2f} % of instances'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return addresses.loc[mask, :]\n",
    "    \n",
    "\n",
    "def get_addresses(path, is_zipped=True):\n",
    "    \"\"\"This gets the address data while discarding\n",
    "    invalid (NaN) instances.\n",
    "    \"\"\"\n",
    "    if is_zipped:\n",
    "        path = _get_zipped_path_for_gpd(path)\n",
    "\n",
    "    addresses = gpd.read_file(path)\n",
    "    addresses = _drop_invalid_addresses(addresses)\n",
    "    \n",
    "    \n",
    "    return addresses\n",
    "\n",
    "path_to_addresses = db_folder / 'Belo Horizonte e Região/ENDERECOS.zip'\n",
    "addresses = get_addresses(path_to_addresses)\n",
    "addresses.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b071b4e7-35a8-4145-be43-75ac9014f0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg:31983\n"
     ]
    }
   ],
   "source": [
    "print(addresses.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a9cc54-24be-4289-ae80-b843232cbbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _turn_floats_to_str(df, cols):\n",
    "    \"\"\"zip codes and house numbers are read in as floats,\n",
    "    this functions turns them to strings, which I prefer\n",
    "    to handling numbers that act as ids.\n",
    "    \n",
    "    TO DO: consider if using regex or\n",
    "    some other method could be safer.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "    cols : array-like\n",
    "        Name of columns to turn to strings\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        df = df.astype({col: int})\n",
    "        df = df.astype({col: str})\n",
    "        \n",
    "        \n",
    "    return df\n",
    "    \n",
    "\n",
    "def _prune_weird_zip_codes(df, zip_code_col):\n",
    "    \"\"\"This removes nonsensical zip_codes, such as some composed\n",
    "    of way less than eight numbers. Mind that zip codes are an 8\n",
    "    digit code, BUT some places (i.e. Greater Sao Paulo) have cases\n",
    "    that start at 0, which might lead to 7 digit instances, in practice.\n",
    "    \"\"\"\n",
    "    df['zip_code_length'] = df[zip_code_col].str.len()\n",
    "    mask = (df['zip_code_length']>=7)\n",
    "    view = df.loc[mask, :]\n",
    "    \n",
    "    deleted = len(df) - len(view)\n",
    "    deleted_percentage = deleted / len(df) * 100\n",
    "    print(\n",
    "        f'{deleted} records have been deleted: {deleted_percentage:.2f}%'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return view.drop(columns=['zip_code_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f1e0ea1-c4dc-4130-9547-98a6561554e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 records have been deleted: 0.00%\n"
     ]
    }
   ],
   "source": [
    "def get_zip_code_place(addresses):\n",
    "    \"\"\"Gets the geolocation of a zip code by assuming it is the\n",
    "    same as the building that lies by the middle of the street section.\n",
    "    \"\"\"\n",
    "    addresses.sort_values(['CEP', 'NUMERO_IMO'], inplace=True)\n",
    "    addresses = _turn_floats_to_str(addresses, ['CEP', 'NUMERO_IMO'])\n",
    "    addresses = _prune_weird_zip_codes(addresses, 'CEP')\n",
    "\n",
    "    locations = {}\n",
    "    for zip_code,group in addresses.groupby('CEP'):\n",
    "        # MEMENTO: the sorting above makes the iloc operation below to act\n",
    "        # as a median calculation, but in a way that ensures the house \n",
    "        # number exists in the list. That is, if the group's length is even,\n",
    "        # the median would be the average of the two middle values, resulting\n",
    "        # in a house number that does not exist.\n",
    "        middle_house_number = group.NUMERO_IMO.iloc[len(group)//2]\n",
    "        mask = (group.CEP==zip_code) & (group.NUMERO_IMO==middle_house_number)\n",
    "        \n",
    "        # .loc returns series when you do boolean indexing because \n",
    "        # chances are that you have multiple match cases. \n",
    "        loc = group.loc[mask,'geometry']\n",
    "        locations[zip_code] = loc.to_numpy()[0]\n",
    "    \n",
    "    locations = pd.DataFrame.from_dict(locations,\n",
    "                                       orient='index',\n",
    "                                       columns=['geometry'])\n",
    "    locations.index.name = 'zip_code'\n",
    "    locations = gpd.GeoDataFrame(locations,\n",
    "                                 crs=F'EPSG:{addresses.crs.to_epsg()}',\n",
    "                                 geometry='geometry',)\n",
    "    \n",
    "    \n",
    "    return locations.reset_index()\n",
    "\n",
    "\n",
    "zip_code_locations = get_zip_code_place(addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9900687-f8a6-4e35-87b4-d72c4ef00d4b",
   "metadata": {},
   "source": [
    "### RAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a0a06b3-2f6d-49f6-9fee-2a36f4203084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fix_ibgeID(ibgeID):\n",
    "    \"\"\"Usually, IBGE's code with 7 digits is utilized,\n",
    "    but RAIS uses the 6-digit version in the files \n",
    "    I've dealt with so far.\n",
    "    \"\"\"\n",
    "    str_ibgeID = str(ibgeID) \n",
    "    if len(str_ibgeID) > 6:\n",
    "        str_ibgeID = str_ibgeID[:-1]\n",
    "    \n",
    "    \n",
    "    return int(str_ibgeID)\n",
    "\n",
    "\n",
    "def parse_job_opp_data(path, ibgeID, sep, encoding):\n",
    "    \"\"\"Gets slice of job opportunities data from the registry\n",
    "    of the municipalities of interest. It also removes anomalies\n",
    "    in the zip code records.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str or Pathlib object\n",
    "    ibgeID : int\n",
    "        IBGE Code for the municipality of interest\n",
    "        (without the verifying digit, i.e. a 6-digit code).\n",
    "    sep : str\n",
    "        Delimiter to use\n",
    "    encoding : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    jobs : DataFrame\n",
    "    \"\"\"\n",
    "    jobs = pd.read_csv(path,\n",
    "                       sep=sep,\n",
    "                       encoding=encoding,)    \n",
    "    to_drop = ['Bairros SP', \n",
    "               'Distritos SP', 'Regiões Adm DF',\n",
    "               'Bairros RJ', 'Bairros Fortaleza',]\n",
    "    jobs.drop(columns=to_drop, inplace=True)\n",
    "    \n",
    "    ibgeID = _fix_ibgeID(ibgeID)\n",
    "    # TO DO: allow list of ibgeID's\n",
    "    jobs = jobs.loc[jobs.Município==ibgeID]\n",
    "    jobs.dropna(subset=['CEP Estab'], inplace=True)\n",
    "    jobs = _turn_floats_to_str(jobs, ['CEP Estab'])\n",
    "    jobs = _prune_weird_zip_codes(jobs, 'CEP Estab')\n",
    "    \n",
    "    \n",
    "    return jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80ffc23b-2f0d-4e69-84cf-1706ceb5c2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 records have been deleted: 0.00%\n"
     ]
    }
   ],
   "source": [
    "path_to_jobs = db_folder / 'RAIS_Estabelecimentos/ESTB2017.zip'\n",
    "\n",
    "jobs = parse_job_opp_data(path_to_jobs,\n",
    "                          ibgeID,\n",
    "                          sep=';',\n",
    "                          encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c339c5-6c72-462d-9597-6da8d97e9d0d",
   "metadata": {},
   "source": [
    "Next, jobs will be selected based on their class in (IBGE's) _National Classification of Economic Activity_ (CNAE 2.0) — refer to < https://bit.ly/cnae_2-0 > for more information and documentation.\n",
    "\n",
    "The main rationale is that only jobs that are more closely related to urban labor or consumer market dynamics are modeled, as those are mostly determined from within the city. Contrarily, the industrial sector is mostly located in order to comply with larger economic circuits (see, e.g., Flavio Villaca or Milton Santos) and with instances of power far beyond the scope of the city. There are also job classes that follow a rationale that is not economic – or should not be –, such as the distribution of some public infrastructure and services – e.g., schools or high-complexity health care. \n",
    "\n",
    "With that in mind, decisions have been made ad hoc, during a quick look throughout CNAE 2.0’s class structure. In that context, it is possible that imprecisions and inconsistencies arise, specially because class definitions may be somewhat vague on occasion, thus making it harder to frame clear distinctions amongst jobs. A more thorough analysis would be one that goes through subclasses, which amount to 1301. But it does not seem at all necessary to delve into such level of detail for the time being.\n",
    "\n",
    "Once such general considerations are established, some more specific commentaries are in order. CNAE’s classes are grouped under umbrella sections and the following comments are organized accordingly:\n",
    "1.\t**A** —_Agriculture, Livestock, Forest Produces, Fishing and Aquiculture_: these are removed from job totals since that should be more in line with the literature review.\n",
    "2.\t**B** — _Extractive Industry_: these are removed as well, also because of the theoretical framework.\n",
    "3.\t**C** — _Converting industry_: those are mostly removed, the exception being some classes which _might_ also be associated with craftsmanship and manual labor developed in small facilities (even households) — see CNAE 2.0 documentation (pp. 160-161).\n",
    "4.\t**D** — _Electricity and Gas_: all have been excluded.\n",
    "5.\t**E** — Water, Sewage, Waste Management and Decontamination_: all classes have been excluded.\n",
    "6.\t**F** — _Construction Industry_: I retained only classes associated with administrative functions and small construction works. Large building and infrastructural works have been left out. I assumed the latter are more closely associated with construction sites, which I believe do not follow quite the same location dynamics as the uses I’m trying to model.\n",
    "7.\t**G** —_Commerce and Vehicle and Motorcycle Repair Shops_: all have been retained for analysis, although it is arguable as to whether is valid to consider wholesale as obeying the same locational mechanisms as the other classes — particularly for instances of wholesale of specialized products.\n",
    "8.\t**H** —_Transport, Storage and Postal Services_: I assumed employment to be mostly tied to administrative offices, which most likely relocate to remain close to other complementary services — law, financial etc. As for the matter of freight, cargo and the like, there may also be administrative instances, but there might personnel working I warehouses and similar facilities. Tha is, on the one hand, such places could obey a rationale that aims at optimizing logistic efficiency; but on the other, locational efficiency can mean close proximity to the city's reatil clusters, which imply co-location. Some of these might be strong assumptions, but in the absence of more detailed information, all classes in the transport section have been preliminarily maintained.\n",
    "\n",
    "All classes contained in the following sections have been retained, as the ties between their locational rationale and the need for agglomeration economies seem self-evident:\n",
    "    \n",
    "9.\t**I** — _Food and Lodgings_\n",
    "10.\t**J** — _Information and Communication Services_\n",
    "11.\t**K** — _Finance, Insurance, and Related Services_\n",
    "12.\t**L** — _Real Estate Management_\n",
    "13.\t**M** — _Professional, Scientific, and Technical Services_\n",
    "14.\t**N** — _Management and Complementary Services_\n",
    "\n",
    "The following again need commentary:\n",
    "\n",
    "15.\t**O** —_Public Administration, Defense and Social Security_: all classes will be used, although I have no consolidated position on these. They might constitute a chicken and egg problem. On the one hand, proximity to the public bureaucracy might stimulate some degree of centrality restructuring. On the other, aiming for capillarity, it is possible that smaller offices are distributed throughout the city’s centralities so as to attend the population. \n",
    "16.\t**P** —_Education_: these will be left out, as these are assumed to locate in a way that maximizes populational coverage. And there is evidence to suggest reasonable capillarity (Paiva Neto et al., 2017).\n",
    "17.\t**Q** —_Health_: only job classes pertaining to private physicians, clinics, laboratory services and similar activities have been maintained. Literature review suggests these tend to cluster in urban centralities and are indeed used to compose some centrality metrics. Higher complexity medical services, hospitals, SUS management and research facilities are not included.\n",
    "18.\t**R** —_Arts, Culture, Sports, and Recreation_: all classes under this section are maintained except for (a) Cultural and Environmental Heritage, and (b) clubs and theme parks.\n",
    "19.\t**S** —_Other activities and Services_: Employers's associations, Unions and other associations are not included. While service jobs are retained.\n",
    "20.\t**T** —_Domestics Services_: these are made up of housemaids and are not assumed to behave according to mechanisms of their own. Hence, those jobs are not considered in the model.\n",
    "21.\t**U** —_International and Foreign Institutions_: such international bodies — e.g., UNO, IMF, embassies etc. — are not assumed to locate according to strict market dynamics. Hence, they are not considered as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ecc9c-8a16-4e68-ab76-d15ae6bcec2e",
   "metadata": {},
   "source": [
    "\n",
    "With that in mind, the appropriate CNAE 2.0's job class ID's have been selected and gathered in a text file.\n",
    "Class IDs have the following structure: dd.dd-d, where d stands for a decimal digit. \n",
    "\n",
    "There are some instances, however, that are simply represented with dd. That corresponds to something CNAE calls a a _division_, and each of those divisions contains a number of classes that are all included for analysis.\n",
    "\n",
    "Mind that in RAIS, IDs are simply represented as ddddd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cfaf5a0-0fb4-410f-bfbf-a6d55813a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_IDs_to_keep = pd.read_csv(db_folder / 'CNAE_job_classes_to_keep.txt',\n",
    "                              header=None,)\n",
    "# pd.read_csv returns a single column DataFrame,\n",
    "# and I need a Series for the solution I thought of\n",
    "job_IDs_to_keep = job_IDs_to_keep.iloc[:,0]\n",
    "\n",
    "# This takes a column containing dd.dd-d and expands it\n",
    "# into three columns as per the following scheme:\n",
    "# {col1: dd, col2: dd, col3: d}.\n",
    "#\n",
    "# Division numbers are expanded like so: \n",
    "# {col1: dd, col2: nan, col3: nan}\n",
    "regex = r'(\\d\\d)\\.?(\\d\\d)?\\-?(\\d)?'\n",
    "job_IDs_to_keep = job_IDs_to_keep.str.extract(regex)\n",
    "\n",
    "# This gets class ID parts extracted above and combines them\n",
    "# into a single string dddddd. \n",
    "classes_to_keep = [a + b + c\n",
    "                   for a,b,c \n",
    "                   in job_IDs_to_keep.itertuples(index=False)\n",
    "                   if pd.notnull(b)]\n",
    "\n",
    "# This creates a list of division IDs\n",
    "divisions_to_keep = [a\n",
    "                     for a,b,c \n",
    "                     in job_IDs_to_keep.itertuples(index=False)\n",
    "                     if pd.isnull(b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4880bc6f-8615-4dcb-8bdd-5856ce15f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.29 of employment has been retained\n"
     ]
    }
   ],
   "source": [
    "# ID classes have been parsed as int\n",
    "jobs = jobs.astype({'CNAE 2.0 Classe': str})\n",
    "\n",
    "condition_a = jobs['CNAE 2.0 Classe'].isin(classes_to_keep)\n",
    "\n",
    "# This takes column with class IDs and expands it into two.\n",
    "# That is, from {col: ddddd} we get {col1: dd, col2: ddd}\n",
    "regex = r'(\\d\\d)(\\d{3})'\n",
    "partitioned_IDs = jobs['CNAE 2.0 Classe'].str.extract(regex)\n",
    "job_divisions = partitioned_IDs.iloc[:,0]\n",
    "\n",
    "condition_b = job_divisions.isin(divisions_to_keep)\n",
    "\n",
    "mask = condition_a | condition_b\n",
    "job_slice = jobs.loc[mask]\n",
    "\n",
    "retained_percentage = (job_slice['Qtd Vínculos Ativos'].sum()\n",
    "                       / jobs['Qtd Vínculos Ativos'].sum()\n",
    "                       * 100)\n",
    "print(f'{retained_percentage:.2f} of employment has been retained')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa011c-fa13-458d-a082-c4c2bd4b99de",
   "metadata": {},
   "source": [
    "Once jobs are selected based on the above criteria, columns that are not deemed strictly relevant for analysis will be dropped. Finally, job data will be spatial joined with the hexagons. Since 2014 RAIS provides the zip code for each registered job, while Belo Horizonte's City Hall provides the geolocation of all zip codes in the municipality, all of which combined allow spatial joining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f329d4d2-f451-4ab8-a955-e264992f9ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_up_job_data(data):\n",
    "    to_drop = [\n",
    "        'CNAE 2.0 Classe', 'CNAE 95 Classe', \n",
    "        'Qtd Vínculos CLT', 'Qtd Vínculos Estatutários', \n",
    "        'Ind Atividade Ano','Ind CEI Vinculado',\n",
    "        'Ind Estab Participa PAT', 'Ind Rais Negativa',\n",
    "        'Ind Simples', 'Município', 'CNAE 2.0 Subclasse',\n",
    "        'Tamanho Estabelecimento', 'Tipo Estab',\n",
    "        'Tipo Estab.1', 'UF',\n",
    "            ]\n",
    "    df = data.drop(columns=to_drop)\n",
    "    \n",
    "    new_names = {\n",
    "        'Qtd Vínculos Ativos': 'jobs',\n",
    "        'Natureza Jurídica': 'business_structure',\n",
    "        'IBGE Subsetor': 'ibge_subsector',\n",
    "        'CEP Estab': 'zip_code',\n",
    "            }\n",
    "    df.rename(columns=new_names, inplace=True)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "job_slice = tidy_up_job_data(job_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de3ec209-5907-47ba-8b40-42d5a6c555f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>jobs</th>\n",
       "      <th>business_structure</th>\n",
       "      <th>ibge_subsector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (610753.906 7794914.788)</td>\n",
       "      <td>2</td>\n",
       "      <td>2062</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (610753.906 7794914.788)</td>\n",
       "      <td>21</td>\n",
       "      <td>2232</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         geometry  jobs  business_structure  ibge_subsector\n",
       "0  POINT (610753.906 7794914.788)     2                2062              20\n",
       "1  POINT (610753.906 7794914.788)    21                2232              22"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_slice = zip_code_locations.merge(job_slice,\n",
    "                                     how='inner',)\n",
    "job_slice.drop(columns='zip_code', inplace=True)\n",
    "job_slice.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d324b3e-ccb9-4d08-9376-afb040a8717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sjoin_jobs(hex_, job_slice):\n",
    "    left_gdf = hex_.reindex(columns=['geometry'])\n",
    "    right_gdf = job_slice.reindex(columns=['jobs', 'geometry'])\n",
    "    \n",
    "    joined_jobs = gpd.sjoin(left_gdf,\n",
    "                            right_gdf,\n",
    "                            how='left',\n",
    "                            op='contains',)\n",
    "    \n",
    "    \n",
    "    return joined_jobs.drop(columns=['index_right', 'geometry'])\n",
    "\n",
    "\n",
    "def _totalize_jobs(joined_jobs):\n",
    "    idx_name = joined_jobs.index.name\n",
    "    gdf = joined_jobs.reset_index()\n",
    "    \n",
    "    \n",
    "    return gdf.groupby(idx_name).sum()\n",
    "\n",
    "\n",
    "def input_jobs_into_hexes(hex_, job_slice):\n",
    "    \"\"\"Takes jobs selected above and performs a spatial join\n",
    "    with the base haxagonal grid. \n",
    "    \n",
    "    # TO DO: think of allowing for a spatial join based on\n",
    "    ibge subsectors of interest.\n",
    "    \"\"\"\n",
    "    joined_jobs = _sjoin_jobs(hex_, job_slice)\n",
    "    jobs_by_hex = _totalize_jobs(joined_jobs)\n",
    "    \n",
    "    \n",
    "    return hex_.merge(jobs_by_hex,\n",
    "                      how='left',\n",
    "                      left_index=True,\n",
    "                      right_index=True,)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "225d5705-8bee-496f-8263-5cbccc2a68a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663,678 jobs have been inputted from a total of 675,241: that amounts to 98.3 %\n"
     ]
    }
   ],
   "source": [
    "hexagons_with_jobs = input_jobs_into_hexes(hex_, job_slice)\n",
    "\n",
    "inputted = hexagons_with_jobs.jobs.sum()\n",
    "total = job_slice.jobs.sum()\n",
    "percentage = inputted / total * 100\n",
    "\n",
    "print(\n",
    "    f'{inputted:,.0f} jobs have been inputted',\n",
    "    f'from a total of {total:,.0f}: that amounts to {percentage:.1f} %'\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d3a95b-bbb3-4ff7-a5af-1bd36544557b",
   "metadata": {},
   "source": [
    "That small percentage of jobs has been \"lost\" because they were located over land uses that are not deemed active — refer to script A00. That conclusion has been reached by means of a visual inspection of the land uses layer, of the hexagonal grid, and of the zip code locations. That visual analysis was made with the aid of QGIS, as plotting it here, using folium, tended to crash my web browser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eff8f787-88e3-4d04-87fa-7c8439d8e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "hexagons_with_jobs.to_file(path_to_hexes, layer='2017', driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c0d82-89e8-449e-bc3e-8175455e2130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
